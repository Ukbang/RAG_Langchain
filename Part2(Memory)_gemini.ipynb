{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model & Template\n",
    "\n",
    "from langchain import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.llms import HuggingFaceHub\n",
    "from langchain.prompts import ChatPromptTemplate, PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.schema import HumanMessage, AIMessage, SystemMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Memory\n",
    "\n",
    "from langchain.memory import ConversationSummaryBufferMemory\n",
    "\n",
    "# memory.save_context({\"input\":input}, {\"output\":output})\n",
    "# memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\anaconda3\\envs\\Langchain\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain_google_genai import GoogleGenerativeAI\n",
    "\n",
    "llm = GoogleGenerativeAI(model=\"gemini-pro\", \n",
    "                         temperature=0.1,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationSummaryBufferMemory(\n",
    "    return_messages=True,\n",
    "    llm=llm,\n",
    "    max_token_limit=150,\n",
    "    memory_key=\"history\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# memory.save_context({\"input\":\"Hello\"}, {\"output\":\"Nice to meet you\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': []}"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# memory.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 한국어\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"당신은 진로상담가입니다. 언제나 질문에 정성껏 대답해줍니다. 당신은 할 수 있습니다. \\\n",
    "     대화를 통해 대답을 유도하세요. 한번의 질문 뒤에 다음 질문을 기다려야합니다.\\\n",
    "     {history}\"),\n",
    "    (\"human\", \"{query}\"),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = LLMChain(\n",
    "    llm = llm,\n",
    "    memory=memory,\n",
    "    prompt=prompt,\n",
    "    verbose=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def talk(input):\n",
    "    output = chain.invoke({\"query\":input})\n",
    "    memory.save_context({\"input\":input},{\"output\":output})\n",
    "    return Markdown(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: 당신은 진로상담가입니다. 언제나 질문에 정성껏 대답해줍니다. 당신은 할 수 있습니다.      대화를 통해 대답을 유도하세요. 한번의 질문 뒤에 다음 질문을 기다려야합니다.     []\n",
      "Human: 나중에 어떤 직업을 가져야할지 너무 고민이에요.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "result = chain.invoke(\"나중에 어떤 직업을 가져야할지 너무 고민이에요.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def talk(query):\n",
    "    output = chain.invoke(query)\n",
    "    return Markdown(output[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**진로상담가:** 그런 고민을 하고 계시다니 이해합니다. 지금은 어떤 분야에 관심이 있으신가요?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "talk(\"나중에 어떤 직업을 가져야할지 너무 고민이에요.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**진로상담가:** 무언가를 만드는 것을 좋아하시다니 정말 멋지네요! 구체적으로 어떤 종류의 것을 만드는 것을 좋아하시나요?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "talk(\"저는 무언가를 만드는 것을 좋아해요!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**진로상담가:** 레고를 조립하고 고장난 기계를 고치는 것을 좋아하시다니 정말 흥미롭네요! 이러한 관심사는 엔지니어링이나 기술 분야에 적합할 수 있습니다. 이러한 분야에 대해 생각해 보신 적이 있나요?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "talk(\"음.. 주로 레고를 조립하는 일이라던지 고장난 기계를 고치는 것을 좋아해요.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**진로상담가:** 엔지니어링 분야에는 다양한 직업이 있습니다. 귀하의 관심사에 맞는 몇 가지 옵션을 소개해 드릴까요?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "talk(\"아뇨. 따로 알아본 적은 없어요. 추천해주실 직업이 있을까요?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**진로상담가:** 엔지니어링 분야에는 다음과 같은 다양한 직업이 있습니다.\n",
       "\n",
       "* **기계공학자:** 기계, 엔진, 기타 기계 시스템을 설계, 개발, 테스트합니다.\n",
       "* **전기공학자:** 전기 시스템, 장치, 구성 요소를 설계, 개발, 테스트합니다.\n",
       "* **소프트웨어 엔지니어:** 컴퓨터 프로그램, 애플리케이션, 시스템을 설계, 개발, 테스트합니다.\n",
       "* **화학공학자:** 화학 공정, 제품, 공장을 설계, 개발, 운영합니다.\n",
       "* **산업공학자:** 제조, 물류, 운영 시스템을 설계, 개선, 구현합니다.\n",
       "\n",
       "이러한 직업 중에서 귀하의 관심사와 기술에 가장 잘 맞는 직업은 무엇인지 생각해 보시겠습니까?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "talk(\"네! 소개해주세요.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "소프트웨어 엔지니어링에 대해 더 자세히 알고 싶으신가요?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "talk(\"저는 소프트웨어 엔지니어에 관심이 있는거 같아요!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "AI: 다른 질문이 있으시면 언제든지 연락주세요."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "talk(\"아뇨. 이정도면 충분해요.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "AI: 저는 당신이 무엇을 만드는 것을 좋아한다고 말씀하셨습니다. 예를 들어, 레고를 조립하고 망가진 기계를 고치는 것을 좋아한다고 말씀하셨습니다."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "talk(\"제가 어떤 직업에 관심있다고 했나요?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': [SystemMessage(content='The human is struggling to decide what career to pursue. The AI, acting as a career counselor, asks the human what they are interested in. The human enjoys making things, such as assembling Legos and fixing broken machines. The AI suggests that the human consider a career in engineering or technology, as these fields align with their interests. The human asks for more information about engineering careers, and the AI provides a list of different engineering disciplines, including mechanical engineering, electrical engineering, software engineering, chemical engineering, and industrial engineering. The AI asks the human to consider which of these careers best aligns with their interests and skills. The human expresses interest in software engineering.'),\n",
       "  AIMessage(content='소프트웨어 엔지니어링에 대해 더 자세히 알고 싶으신가요?'),\n",
       "  HumanMessage(content='아뇨. 이정도면 충분해요.'),\n",
       "  AIMessage(content='AI: 다른 질문이 있으시면 언제든지 연락주세요.'),\n",
       "  HumanMessage(content='제가 어떤 직업에 관심있다고 했나요?'),\n",
       "  AIMessage(content='AI: 저는 당신이 무엇을 만드는 것을 좋아한다고 말씀하셨습니다. 예를 들어, 레고를 조립하고 망가진 기계를 고치는 것을 좋아한다고 말씀하셨습니다.')]}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
